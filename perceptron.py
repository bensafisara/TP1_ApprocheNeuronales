# -*- coding: utf-8 -*-
"""Perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ddnqlg-qLiFuFMr_pos3G2y9J4_ZCns8
"""

import numpy as np
import random
import math
import matplotlib.pyplot as plt

"""**1. Programmer  l'algorithme du perceptron  a)  version batch et  b)  version
online.**
"""

# version batch 
def versionBatch(W,alph,X,etiq):
  itera_bch=0
  pred=np.ones(len(etiq))#mon tableau d'étiquettes que je vais prédir
  n=len(X)
  W = np.append(1, W)#ajouter le biais à mes poids
  #print(W)
  while not classeCorrectementVecteur(etiq, pred): #tanque les 2 liste ne sont pas pareille je continue
    Dw=0
    for i in range(n):
      itera_bch+=1
      x_ = np.append(1, X[i])
      if np.transpose(W).dot(x_)> 0 :
        pred[i]=1
      else:
        pred[i]=-1
      if pred[i] != etiq[i] :
        Dw = x_.dot(alph*(etiq[i]-pred[i]))
      W=W+Dw
        
    
  return W,pred,itera_bch

#version online
def versionOnline(W,alph,X,etiq):
  pred=np.ones(len(X))
  W = np.append(1, W)
  IT=0
  while not classeCorrectementVecteur(etiq, pred):
    i=random.randint(0, len(X) - 1)#car les vecteurs commence de 0 à n-1
    x_ = np.append(1, X[i])
    IT+=1
    Dw=0
    if np.transpose(W).dot(x_)> 0 :
       pred[i]=1
    else:
       pred[i]=-1
    if pred[i] != etiq[i] :
      Dw = x_.dot(alph*(etiq[i]-pred[i]))
    W=W+Dw
      
    
  return W,pred,IT

def classeCorrectementVecteur(vect1,vect2):
  
  
  if np.array_equal(vect1,vect2):
    
      return True 
  return False

"""Tester la version batch ET / OU / ExempleCours"""

W=np.array([0.4,0.6])
alph=0.8


X_ = np.array([[2,1],[0,-1],[-2,1],[0,2]])
etiq = np.array([1,1,-1,-1])
print(versionBatch(W,alph,X_,etiq))


X_ou= np.array([[0,0],[1,0],[0,1],[1,1]]) 
etiq_ou = np.array([-1,1,1,1])
print(versionBatch(W,alph,X_ou,etiq_ou))

X_et= np.array([[0,0],[1,0],[0,1],[1,1]])
etiq_et = np.array([-1,-1,-1,1])


print(versionBatch(W,alph,X_et,etiq_et))

"""Tester la version Online ET / OU / ExempleCours"""

print(versionOnline(W,alph,X_,etiq))
print(versionOnline(W,alph,X_ou,etiq_ou))
print(versionOnline(W,alph,X_et,etiq_et))

"""**2. Génerer Données  LS  aléatoires.  Construire  un  ensemble  LS  de  P  exemples  en  N+1
dimensions avec un p  erceptron p  rofesseur**  
"""

# Génération de l'ensemble des données pour le Perceptron Professeur
def genererDataset(P, N):
    #si je n'effectue pas la normalisation mes algo ne s'arrete quasiment pas car beaucoup de valeurs après la virgule
    X = np.random.randint(-100,100,(P,N))/100 
    W = np.random.randint(-100,100,N)/100
    
    
    return X,  W
    
genererDataset(100, 10)

def Linear_separability(X,w):
  tau=[]
  for x in X:
       
       if np.dot(w,x)<=0:
           tau += [-1]
           #plt.scatter(X[i,0],X[i,1],c="r")
       else:
           tau += [1]
           #plt.scatter(X[i,0],X[i,1],c="g")
       
  #plt.show
  return tau

"""**3. Apprentissage. Apprendre avec a) la version batch de l'algorithme du perceptron et
b) la  version online.  Pour chaque version faire apprendre un  perceptron élève W sur
l'ensemble LS obtenu lors de la génération de données.**

R = cos(alpha) = a * b / (|a| * |b|)

Lancer  le  programme  avec  les  valeurs  :  N=2,10,100,500,1000 ;
P=10,100,500,1000. Donner les résultats sous la forme de 2 tableaux (batch et online) où
chaque case affiche la moyenne du nombre d'itérations <IT> et la moyenne du rapport
<R>, sur 50 tirages aléatoires
"""

def ApprentissageEleveOnline(P, N):
    moyenneIT=0
    moyenneR= 0  
    for i in range(50): #50 tirage aléatoires
      X_prof,W_prof=genererDataset(P, N)

      etiq_prof= Linear_separability(X_prof,W_prof)
      W_eleve,pred_eleve,IT = versionOnline(W_prof,alph,X_prof,etiq_prof)
      moyenneIT=moyenneIT+IT
      W_prof = np.append(1, W_prof)
      #print("etiquette professeur",etiq_prof)
      #print("etiquette professeur",pred_eleve)
      print("\n")
      R = math.cos(np.dot(W_prof, W_eleve) / np.dot(np.linalg.norm(W_prof), np.linalg.norm(W_eleve)))
      moyenneR= moyenneR+R
    moyenneIT=moyenneIT/50
    moyenneR= moyenneR/50


    return  moyenneIT,moyenneR



#############
moyenneIT ,moyenneR= ApprentissageEleveOnline(10, 2)
print(moyenneIT)
print(moyenneR)

"""version online :



**P=10**

p=10 N=2 moyIT => 51.74 moyR=>0.84

p=10 N=10 moyIT => 44.04  moyR=>0.846

p=10 N=100 moyIT =>32.5 moyR=>0.8106

p=10 N=500 moyIT =>23.28  moyR=> 0.69

p=10 N=1000 moyIT =>31.3  moyR=>0.715


**P=100**

p=100 N=2 moyIT => 2754.22 moyR=>0.813

p=100 N=10 moyIT => 2045.64 moyR=>0.663

p=100 N=100 moyIT =>903.02 moyR=>0.79

p=100 N=500 moyIT =>  735.9  moyR=>0.93

p=100 N=1000 moyIT => 795.24 moyR=>0.96


**P=500**

p=500 N=2 moyIT =>82970.16 moyR=> 0.82

p=500 N=10 moyIT =>  87868.28 moyR=> 0.68

p=500 N=100 moyIT =>22065.9  moyR=> 0.587

p=500 N=500 moyIT =>8179.02 moyR=> 0.793


p=500 N=1000 moyIT => 6194.56 moyR=> 0.88


**P=1000**

p=1000 N=2 moyIT => 392813.04 moyR=>0.834

p=1000 N=10 moyIT => 400228.08 moyR=> 0.65

p=1000 N=100 moyIT => 117424.94 moyR=> 0.563

p=1000 N=500 moyIT =>27000.04 moyR=>0.680

p=1000 N=1000 moyIT => 18724.86  moyR=>0.792




"""

def ApprentissageEleveBatch(P, N):
    moyenneIT=0
    moyenneR= 0
    for i in range(50):#50 tirages
      X_prof,W_prof=genererDataset(P, N)
      etiq_prof= Linear_separability(X_prof,W_prof)
      
      W_eleve,pred_eleve,IT = versionBatch(W_prof,alph,X_prof,etiq_prof)
      moyenneIT=moyenneIT+IT
      W_prof = np.append(1, W_prof)
      print("etiquette professeur",etiq_prof)
      print("etiquette professeur",pred_eleve)
      print("\n")
      R = math.cos(np.dot(W_prof, W_eleve) / np.dot(np.linalg.norm(W_prof), np.linalg.norm(W_eleve)))
      moyenneR= moyenneR+R
    moyenneIT=moyenneIT/50
    moyenneR= moyenneR/50


    return  moyenneIT,moyenneR



##########
moyenneIT ,moyenneR= ApprentissageEleveBatch(1000, 2)

print(moyenneIT)
print(moyenneR)

"""Version Batch

P=10

p=10 N=2 moyIT =>91.4  moyR=>0.83

p=10 N=10 moyIT =>45.6  moyR=>0.849

p=10 N=100 moyIT =>29.4 moyR=>0.83

p=10 N=500 moyIT =>22.0 moyR=>0.738

p=10 N=1000 moyIT =>19.2 moyR=>0.694


P=100

p=100 N=2 moyIT =>9346.0  moyR=>0.828

p=100 N=10 moyIT => 6126.0 moyR=>0.664

p=100 N=100 moyIT =>2556.0 moyR=>0.817

p=100 N=500 moyIT => 1658.0 moyR=>0.966

p=100 N=1000 moyIT =>1334.0  moyR=>0.98


**P=500**

p=500 N=2 moyIT =>588280.0 moyR=>0.83

p=500 N=10 moyIT => 353500.0   moyR=> 0.64

p=500 N=100 moyIT => 121370.0 moyR=>0.589

p=500 N=500 moyIT => 46660.0 moyR=> 0.81

p=500 N=1000 moyIT => 36770.0 moyR=>0.91



**P=1000**

p=1000 N=2 moyIT => 827020.0 moyR=>0.82

p=1000 N=10 moyIT =>  2149060.0 moyR=>0.644

p=1000 N=100 moyIT =>734980.0 moyR=>0.56

p=1000 N=500 moyIT => 232740.0 moyR=>0.69

p=1000 N=1000 moyIT => 172820.0 moyR=>0.81
"""